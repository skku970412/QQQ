{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10894f71",
   "metadata": {},
   "source": [
    "# QQQ Quantization Experiments\n",
    "\n",
    "This notebook runs multiple quantization experiments using `examples/quant_model.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45902a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "# Set environment variables for multiple GPUs\n",
    "os.environ['PYTHONPATH'] = '.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13bb02b",
   "metadata": {},
   "source": [
    "## Experiment 1: basic quantization with multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b48f007",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3,4,5'\n",
    "!python3 examples/quant_model.py \\\n",
    "    --model_path ./models/Llama-3.1-8B \\\n",
    "    --tokenizer_path ./models/Llama-3.1-8B \\\n",
    "    --dtype float16 \\\n",
    "    --smooth false \\\n",
    "    --rotation true \\\n",
    "    --dataset wikitext2 \\\n",
    "    --nsamples 128 \\\n",
    "    --w_quantizer FixedQuantize \\\n",
    "    --w_group_size -1 \\\n",
    "    --gptq_mse true \\\n",
    "    --gptq_groupsize -1 \\\n",
    "    --save_path ./qqq-llama3-8b_test_more_samples \\\n",
    "    --batch_size 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bb322b",
   "metadata": {},
   "source": [
    "## Experiment 2: activation per-channel and weight per-group quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c613c6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1,2,5'\n",
    "!python3 examples/quant_model.py \\\n",
    "    --model_path ./models/Llama-3.1-8B \\\n",
    "    --tokenizer_path ./models/Llama-3.1-8B \\\n",
    "    --dtype float16 \\\n",
    "    --smooth false \\\n",
    "    --rotation true \\\n",
    "    --dataset wikitext2 \\\n",
    "    --nsamples 128 \\\n",
    "    --w_quantizer GroupFixedQuantize \\\n",
    "    --w_group_size 128 \\\n",
    "    --gptq_mse true \\\n",
    "    --gptq_groupsize 128 \\\n",
    "    --save_path ./qqq-llama3-8b_g128 \\\n",
    "    --batch_size 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0380be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2,3,5'\n",
    "!python3 examples/quant_model.py \\\n",
    "    --model_path ./models/Llama-3.1-8B \\\n",
    "    --tokenizer_path ./models/Llama-3.1-8B \\\n",
    "    --dtype float16 \\\n",
    "    --smooth false \\\n",
    "    --rotation false \\\n",
    "    --dataset wikitext2 \\\n",
    "    --nsamples 128 \\\n",
    "    --w_quantizer FixedQuantize \\\n",
    "    --w_group_size -1 \\\n",
    "    --gptq_mse true \\\n",
    "    --gptq_groupsize -1 \\\n",
    "    --save_path ./qqq-llama3-8b_sdpa \\\n",
    "    --batch_size 1\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
