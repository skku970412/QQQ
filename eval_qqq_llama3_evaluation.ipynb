{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b6fce6",
   "metadata": {},
   "source": [
    "# QQQ LLaMA3 Evaluation\n",
    "\n",
    "This notebook runs the `eval_model.py` script on the specified model path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd04bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "# Set environment variables\n",
    "os.environ['PYTHONPATH'] = '.'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4030110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qqq-llama3-8b_base/Llama-3.1-8B\n",
    "# Run the evaluation\n",
    "!python3 examples/eval_model.py \\\n",
    "    --model_path /home/eiclab/eiclab04/urp2025/QQQ_git/QQQ/qqq-llama3-8b_base/Llama-3.1-8B \\\n",
    "    --tokenizer_path /home/eiclab/eiclab04/urp2025/QQQ_git/QQQ/qqq-llama3-8b_base/Llama-3.1-8B \\\n",
    "    --eval_ppl \\\n",
    "    --batch_size 2 \\\n",
    "    --max_length 2048\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c4b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qqq-llama3-8b_g128\n",
    "# Run the evaluation script with the specified model and tokenizer paths\n",
    "!python3 examples/eval_model.py \\\n",
    "    --model_path /home/eiclab/eiclab04/urp2025/QQQ_git/QQQ/qqq-llama3-8b_g128/Llama-3.1-8B \\\n",
    "    --tokenizer_path /home/eiclab/eiclab04/urp2025/QQQ_git/QQQ/qqq-llama3-8b_g128/Llama-3.1-8B \\\n",
    "    --eval_ppl \\\n",
    "    --batch_size 2 \\\n",
    "    --max_length 2048\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
