## ğŸ“¦ QQQ: LLaMA 3.1â€“8B ì „ìš© W4A8 ì–‘ìí™” íˆ´í‚·

**QQQ**ëŠ” **LLaMA 3.1 8B ëª¨ë¸ ì „ìš©**ìœ¼ë¡œ ì„¤ê³„ëœ ì—°êµ¬ ê¸°ë°˜ì˜ W4A8 (4-bit weight, 8-bit activation) í¬ìŠ¤íŠ¸ íŠ¸ë ˆì´ë‹ ì–‘ìí™”(PTQ) íˆ´í‚·ì…ë‹ˆë‹¤.  
ë‹¤ë¥¸ ëª¨ë¸ì€ ì§€ì›í•˜ì§€ ì•Šìœ¼ë©°, ëª¨ë“  ê¸°ëŠ¥ì€ **LLaMA 3.1â€“8Bì—ë§Œ ìµœì í™”**ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

---

### ğŸ”‘ ì£¼ìš” ê¸°ëŠ¥

- **W4A8 ì „ì²´ ì–‘ìí™” íŒŒì´í”„ë¼ì¸**
  - SmoothQuant ìŠ¤íƒ€ì¼ì˜ í™œì„±í™” í‰í™œí™” ì§€ì› (ì„ íƒì )
  - í—¤ì‹œì•ˆ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ë³´ì •
- **ì»¤ìŠ¤í…€ CUDA GEMM ì»¤ë„**
  - per-channel ë° per-group ë°©ì‹ W4A8 ì—°ì‚°
  - cuBLAS FP16 ëŒ€ë¹„ ìµœëŒ€ **3.7Ã—** ì†ë„ í–¥ìƒ
- **ì •í™•ë„ í–¥ìƒ ê¸°ìˆ **
  - ì„ íƒì  Weight Rotation
  - MSE ìµœì í™” GPTQ ë¸”ë¡
- **vLLM í†µí•©**
  - `--quantization qqq` ì˜µì…˜ìœ¼ë¡œ Marlin ì»¤ë„ ê¸°ë°˜ ê³ ì† ì¶”ë¡ 

---

### âœ… ì§€ì› ëª¨ë¸

| ëª¨ë¸ ì´ë¦„              | ì§€ì› ì—¬ë¶€ |
|------------------------|-----------|
| âœ… LLaMA 3.1 8B         | ì§€ì›ë¨     |
| âŒ LLaMA 3.0 / 7B / 13B / 65B | ë¯¸ì§€ì› |
| âŒ Qwen, Mistral, OPT, Bloom ë“± | ë¯¸ì§€ì› |

> ğŸ“Œ ë³¸ ì €ì¥ì†ŒëŠ” **LLaMA 3.1â€“8B ì „ìš©**ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ëª¨ë¸ì— ì ìš©í•˜ë©´ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

### âš™ï¸ ì„¤ì¹˜

```bash
git clone https://github.com/skku970412/QQQ.git
cd QQQ
conda env create -f environment.yml
conda activate qqq-py39
pip install -v -e .
ğŸ“œ License & Citation
QQQ is released under the Apache 2.0 license. If you use this codebase or its kernels in your research, please cite:

@article{zhang2024qqq,
  title   = {QQQ: Quality Quattuor-Bit Quantization for Large Language Models},
  author  = {Ying Zhang and Peng Zhang and Mincong Huang and Jingyang Xiang and Yujie Wang and Chao Wang and Yineng Zhang and Lei Yu and Chuan Liu and Wei Lin},
  journal = {arXiv preprint arXiv:2406.09904},
  year    = 2024
}
Happy quantising! ğŸ‰
