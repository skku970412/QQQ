# QQQ â€” Conda Environment Setup Guide

**Purposeâ€¯:** spin up a fully reproducible PythonÂ +Â CUDA environment so you can **quantize, evaluate and run W4A8 QQQ models** right after cloning the repo.

---

## 1â€‘Step InstallÂ *(recommended)*

The repo already ships with an `environment.yml` describing every required package (PythonÂ 3.9, PyTorchÂ 2.6Â +Â CUDAÂ 12.4, TransformersÂ 4.38.2, etc.).Â Use it to create the entire environment in one shot.

```bash
# 1Â Clone QQQ
git clone https://github.com/skku970412/QQQ.git
cd QQQ

# 2Â (optional) delete the hardâ€‘coded prefix line
#    because it contains the path of the authorâ€™s machine
sed -i '/^prefix:/d' environment.yml          #Â Linux /Â macOS
#  â–ºÂ WindowsÂ PowerShell
#  (Get-Content environment.yml) -notmatch '^prefix:' | Set-Content environment.yml

# 3Â Create & activate the conda envÂ (â‰ˆÂ 5â€‘10Â min)
conda env create -f environment.yml
conda activate qqq-py39          #Â env name comes from environment.yml
```

### Quick sanityâ€‘check

```bash
python - <<'PY'
import torch, transformers, accelerate, platform
print("CUDAÂ ", torch.version.cuda, "| GPUÂ =", torch.cuda.get_device_name(0))
print("PyTorchÂ Â Â Â Â ", torch.__version__)
print("Transformers", transformers.__version__)
print("AccelerateÂ Â ", accelerate.__version__)
print("PythonÂ Â Â Â Â ", platform.python_version())
PY
```

If all versions print without errors, you are good to go.

---

## Minimal installÂ â€” build your own env

Need a lighter test environment or different CUDA version?Â Start from the **minimal** template below and tweak versions as needed.

<details>
<summary>ðŸ”§Â `minimal_environment.yml` template</summary>

```yaml
name: qqq-min
channels:
  - conda-forge
  - nvidia
  - defaults
dependencies:
  #Â Core
  - python=3.9
  - pip
  #Â GPU stack (CUDAÂ 12.4 â€” change to cu118 / cu121 â€¦ if required)
  - cudatoolkit=12.4
  - pytorch=2.6.0
  - torchvision=0.21.0
  - torchaudio=2.6.0
  #Â Essential libs
  - accelerate>=1.7
  - zstandard
  - pip:
      - transformers==4.38.2
      - datasets==2.16.1
      - easydict
      - lm_eval==0.4.2
      - fast-hadamard-transform==1.0.4.post1
      - sympy==1.13.1
      - triton==3.2.0
```

</details>

```bash
conda env create -f minimal_environment.yml
conda activate qqq-min
```

> **Different CUDA build?**Â Pair `pytorch` and `cudatoolkit` with the same CUDA tag (e.g. 11.8) or follow the official `pip install torch==â€¦+cu118` instructions from [https://pytorch.org](https://pytorch.org).

---

## Extra setup & handy tips

| Item                      | Notes                                                                                                                                            |
| ------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Environment variables** | An example `env_vars.txt` is provided.Â Typically you only need to adjust `CUDA_HOME` and `LD_LIBRARY_PATH` to your local GPU/CUDA paths.         |
| **Compile C++/CUDA ops**  | Run `pip install -v -e .` once inside the activated env to build QQQâ€™s custom kernels.                                                           |
| **Jupyter notebooks**     | Add `conda install jupyterlab` if you prefer interactive prototyping.                                                                            |
| **Keeping the env fresh** | Sync with the latest commit via `conda env update -f environment.yml --prune` (or `mamba env update â€¦`).                                         |
| **Memory optimisation**   | Huge models (â‰¥Â 30â€¯B) may not fit a single GPU â€” use vLLM, HuggingÂ Face Accelerate, or 4â€‘bit KVâ€‘cache tricks (`bitsandbytes`) to shard / offload. |

---

## Troubleshooting FAQ

| Symptom                          | Fix                                                                                                                                              |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------ |
| `libcublas.so not found`         | Your conda CUDA build and installed NVIDIA driver are mismatched.Â Check `nvidia-smi` and reinstall `pytorchÂ +Â cudatoolkit` matching that driver. |
| Conda dependency solving is slow | Install **mamba** for a 2â€‘3Ã— speedâ€‘up: `conda install -n base -c conda-forge mamba`.                                                             |
| `prefix already exists` error    | A previous env lives at the same path.Â Remove it with `conda env remove -p <path>` or create a new env name using `-n <new_name>`.               |

---

### ðŸš€Â All set!

You can now run `examples/quant_model.py`, `examples/eval_model.py`, or `examples/test_model.py` to **quantize, benchmark, and generate text with your 3.18â€¯B W4A8 QQQ model**.
